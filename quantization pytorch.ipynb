{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-training static quantization (Pytorch) - ResNet18\n",
    "In this notebook, you will be able to see how quantization in PyTorch can result in significant decreases in model size while increasing speed. Note that quantization is currently only supported for CPUs, so we will be utilizing GPUs / CUDA only for training and CPU for testing.\n",
    "Furthermore, while using complex dataset the accuracy might decrease upon quantization. By using a quantization configuration\n",
    "\n",
    "    model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "\n",
    "we can significantly improve on the accuracy. We repeat the same exercise with the recommended configuration for quantizing for x86 architectures. This configuration does the following:\n",
    "1. Quantizes weights on a per-channel basis\n",
    "2. Uses a histogram observer that collects a histogram of activations and then picks quantization parameters in an optimal manner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.quantized.engine = 'fbgemm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.utils.bottleneck as B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and visualize MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: ../data: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(torchvision.datasets.MNIST('../data', train=True, download=True,\n",
    "                                                    transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                    ])),\n",
    "               batch_size=64, shuffle=True, num_workers=1, pin_memory=True)\n",
    "\n",
    "test_loader = DataLoader(torchvision.datasets.MNIST('../data', train=False, \n",
    "                                                    transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                    ])),\n",
    "              batch_size=64, shuffle=True, num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "figure = plt.figure()\n",
    "num_of_images = 20\n",
    "for index in range(1, num_of_images + 1):\n",
    "    plt.subplot(6, 10, index)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet18 model\n",
    "This code is taken from https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py \n",
    "\n",
    "> NOTE: Training uses resnet model as is with addition operation and floating point inputs / outputs.      \n",
    "But when model is quantized while testing addition operation is replaced with FloatFunction and the inputs         / outputs are quantized/dequantized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\n",
    "    \n",
    "    Args:\n",
    "        in_planes: number of channels in input image\n",
    "        out_planes: number of channels produced by convolution\n",
    "        stride: stride of the convolution. Default: 1\n",
    "        groups: Number of blocked connections from input channels to output channels. Default: 1\n",
    "        dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n",
    "        \n",
    "    Returns:\n",
    "        Convoluted layer of kernel size=3, with specified out_planes\n",
    "    \n",
    "    \"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\n",
    "    \n",
    "    Args:\n",
    "        in_planes: number of channels in input image\n",
    "        out_planes: number of channels produced by convolution\n",
    "        stride: stride of the convolution. Default: 1\n",
    "        \n",
    "    Returns:\n",
    "        Convoluted layer of kernel size=1, with specified out_planes\n",
    "        \n",
    "    \"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n",
    "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
    "    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n",
    "    # This variant is also known as ResNet V1.5 and improves accuracy according to\n",
    "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
    "\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None, quantize=False):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.quantize = quantize\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation) # code for Bottleneck\n",
    "        # self.conv1 = conv3x3(inplanes, planes, stride) # code for BasicBlock\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        # added\n",
    "        self.skip_add = nn.quantized.FloatFunctional()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        # Notice the addition operation in both scenarios\n",
    "        if self.quantize:\n",
    "            out = self.skip_add.add(out, identity)\n",
    "        else:\n",
    "            out += identity\n",
    "\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None, quantize=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.quantize = quantize\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride) # diff\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        # FloatFunction()\n",
    "        self.skip_add = nn.quantized.FloatFunctional()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        # Notice the addition operation in both scenarios\n",
    "        if self.quantize:\n",
    "            out = self.skip_add.add(out, identity)\n",
    "        else:\n",
    "            out += identity\n",
    "\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet18(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"ResNet-18 model from\n",
    "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress,\n",
    "                   **kwargs)\n",
    "\n",
    "\n",
    "def resnet34(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"ResNet-34 model from\n",
    "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet('resnet34', BasicBlock, [3, 4, 6, 3], pretrained, progress,\n",
    "                   **kwargs)\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"ResNet-50 model from\n",
    "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet('resnet50', Bottleneck, [3, 4, 6, 3], pretrained, progress,\n",
    "                   **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block=BasicBlock, layers=[2, 2, 2, 2], num_classes=1000, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None, mnist=False, quantize=False):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.quantize = quantize\n",
    "        if mnist:\n",
    "            num_channels = 1\n",
    "        else:\n",
    "            num_channels = 3\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace \n",
    "            # the 2x2 stride with a dilated convolution instead.\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(num_channels, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer, quantize=self.quantize))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer, quantize=self.quantize))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # Input are quantized\n",
    "        if self.quantize:\n",
    "            x = self.quant(x)\n",
    "    \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        # Outputs are dequantized\n",
    "        if self.quantize:\n",
    "            x = self.dequant(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "         # See note [TorchScript super()]\n",
    "        return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    \"\"\" Train the model with given dataset\n",
    "    \n",
    "    Args:\n",
    "        args: args like log interval\n",
    "        model: ResNet model to train\n",
    "        device: CPU/GPU\n",
    "        train_loader: dataset iterator\n",
    "        optimizer: optimizer to update weights\n",
    "        epoch: number of epochs to train for\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    fast_version = True\n",
    "    index = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        index += 1\n",
    "        if fast_version:\n",
    "            if index > 3:\n",
    "                break\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(F.log_softmax(output, dim=-1), target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % args[\"log_interval\"] == 0:\n",
    "            print('{} Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                datetime.now(),\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cuda = False\n",
    "\n",
    "use_cuda = not no_cuda and torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-07 23:20:36.235792 Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.621167\n",
      "2020-10-07 23:20:37.847929 Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.861734\n",
      "2020-10-07 23:20:39.399247 Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.222496\n",
      "2020-10-07 23:20:41.012750 Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.877307\n",
      "2020-10-07 23:20:42.605359 Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.671779\n"
     ]
    }
   ],
   "source": [
    "def main_18():\n",
    " \n",
    "    batch_size = 64\n",
    "    epochs = 5\n",
    "    lr = 0.01\n",
    "    momentum = 0.5\n",
    "    seed = 1\n",
    "    log_interval = 5\n",
    "    save_model = True\n",
    "    no_cuda = False\n",
    "    \n",
    "    use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "    torch.manual_seed(seed)\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    model = ResNet(block=BasicBlock, layers=[2, 2, 2, 2], num_classes=10, mnist=True).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    args = {}\n",
    "    args[\"log_interval\"] = log_interval\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "\n",
    "    if (save_model):\n",
    "        torch.save(model.state_dict(),\"mnist_cnn_18.pt\")\n",
    "\n",
    "main_18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-07 22:37:46.950035 Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.559569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
       "  (quant): QuantStub()\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def main_50():\n",
    " \n",
    "    batch_size = 64\n",
    "    epochs = 1\n",
    "    lr = 0.01\n",
    "    momentum = 0.5\n",
    "    seed = 1\n",
    "    log_interval = 5\n",
    "    save_model = True\n",
    "    no_cuda = False\n",
    "    \n",
    "    use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "    torch.manual_seed(seed)\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    model = ResNet(block=Bottleneck, layers=[3, 4, 6, 3], num_classes=10, mnist=True).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    args = {}\n",
    "    args[\"log_interval\"] = log_interval\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        break\n",
    "\n",
    "    if (save_model):\n",
    "        torch.save(model.state_dict(),\"mnist_cnn.pt\")\n",
    "        \n",
    "\n",
    "    return model\n",
    "\n",
    "model = main_50()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_size_of_model(model):\n",
    "    \"\"\" Print the size of the model.\n",
    "    \n",
    "    Args:\n",
    "        model: model whose size needs to be determined\n",
    "\n",
    "    \"\"\"\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size of the model(MB):', os.path.getsize(\"temp.p\")/1e6)\n",
    "    os.remove('temp.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, quantize=False, fbgemm=False, is_resnet18=False):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Testing with qauntization if quantize=True\n",
    "    if quantize:\n",
    "        if is_resnet18:\n",
    "            modules_to_fuse_old = [['conv1', 'bn1'],\n",
    "                   ['layer1.0.conv1', 'layer1.0.bn1'],\n",
    "                   ['layer1.0.conv2', 'layer1.0.bn2'],\n",
    "                   ['layer1.1.conv1', 'layer1.1.bn1'],\n",
    "                   ['layer1.1.conv2', 'layer1.1.bn2'],\n",
    "                   ['layer2.0.conv1', 'layer2.0.bn1'],\n",
    "                   ['layer2.0.conv2', 'layer2.0.bn2'],\n",
    "                   ['layer2.0.downsample.0', 'layer2.0.downsample.1'],\n",
    "                   ['layer2.1.conv1', 'layer2.1.bn1'],\n",
    "                   ['layer2.1.conv2', 'layer2.1.bn2'],\n",
    "                   ['layer3.0.conv1', 'layer3.0.bn1'],\n",
    "                   ['layer3.0.conv2', 'layer3.0.bn2'],\n",
    "                   ['layer3.0.downsample.0', 'layer3.0.downsample.1'],\n",
    "                   ['layer3.1.conv1', 'layer3.1.bn1'],\n",
    "                   ['layer3.1.conv2', 'layer3.1.bn2'],\n",
    "                   ['layer4.0.conv1', 'layer4.0.bn1'],\n",
    "                   ['layer4.0.conv2', 'layer4.0.bn2'],\n",
    "                   ['layer4.0.downsample.0', 'layer4.0.downsample.1'],\n",
    "                   ['layer4.1.conv1', 'layer4.1.bn1'],\n",
    "                   ['layer4.1.conv2', 'layer4.1.bn2']]\n",
    "        else:\n",
    "            modules_to_fuse_old = [['conv1', 'bn1'],\n",
    "                   ['layer1.0.conv1', 'layer1.0.bn1'],\n",
    "                   ['layer1.0.conv2', 'layer1.0.bn2'],\n",
    "                   ['layer1.0.conv3', 'layer1.0.bn3'],\n",
    "                   ['layer1.1.conv1', 'layer1.1.bn1'],\n",
    "                   ['layer1.1.conv2', 'layer1.1.bn2'],\n",
    "                   ['layer1.1.conv3', 'layer1.1.bn3'],\n",
    "                   ['layer1.2.conv1', 'layer1.2.bn1'],\n",
    "                   ['layer1.2.conv2', 'layer1.2.bn2'],\n",
    "                   ['layer1.2.conv3', 'layer1.2.bn3'],\n",
    "                   ['layer2.0.conv1', 'layer2.0.bn1'],\n",
    "                   ['layer2.0.conv2', 'layer2.0.bn2'],\n",
    "                   ['layer2.0.conv3', 'layer2.0.bn3'],\n",
    "                   ['layer2.0.downsample.0', 'layer2.0.downsample.1'],\n",
    "                   ['layer2.1.conv1', 'layer2.1.bn1'],\n",
    "                   ['layer2.1.conv2', 'layer2.1.bn2'],\n",
    "                   ['layer2.1.conv3', 'layer2.1.bn3'],\n",
    "                   ['layer2.2.conv1', 'layer2.2.bn1'],\n",
    "                   ['layer2.2.conv2', 'layer2.2.bn2'],\n",
    "                   ['layer2.2.conv3', 'layer2.2.bn3'],\n",
    "                   ['layer2.3.conv1', 'layer2.3.bn1'],\n",
    "                   ['layer2.3.conv2', 'layer2.3.bn2'],\n",
    "                   ['layer2.3.conv3', 'layer2.3.bn3'],\n",
    "                   ['layer3.0.conv1', 'layer3.0.bn1'],\n",
    "                   ['layer3.0.conv2', 'layer3.0.bn2'],\n",
    "                   ['layer3.0.conv3', 'layer3.0.bn3'],\n",
    "                   ['layer3.0.downsample.0', 'layer3.0.downsample.1'],\n",
    "                   ['layer3.1.conv1', 'layer3.1.bn1'],\n",
    "                   ['layer3.1.conv2', 'layer3.1.bn2'],\n",
    "                   ['layer3.1.conv3', 'layer3.1.bn3'],\n",
    "                   ['layer3.2.conv1', 'layer3.2.bn1'],\n",
    "                   ['layer3.2.conv2', 'layer3.2.bn2'],\n",
    "                   ['layer3.2.conv3', 'layer3.2.bn3'],\n",
    "                   ['layer3.3.conv1', 'layer3.3.bn1'],\n",
    "                   ['layer3.3.conv2', 'layer3.3.bn2'],\n",
    "                   ['layer3.3.conv3', 'layer3.3.bn3'],\n",
    "                   ['layer3.4.conv1', 'layer3.4.bn1'],\n",
    "                   ['layer3.4.conv2', 'layer3.4.bn2'],\n",
    "                   ['layer3.4.conv3', 'layer3.4.bn3'],\n",
    "                   ['layer3.5.conv1', 'layer3.5.bn1'],\n",
    "                   ['layer3.5.conv2', 'layer3.5.bn2'],\n",
    "                   ['layer3.5.conv3', 'layer3.5.bn3'],\n",
    "                   ['layer4.0.conv1', 'layer4.0.bn1'],\n",
    "                   ['layer4.0.conv2', 'layer4.0.bn2'],\n",
    "                   ['layer4.0.conv3', 'layer4.0.bn3'],\n",
    "                   ['layer4.0.downsample.0', 'layer4.0.downsample.1'],\n",
    "                   ['layer4.1.conv1', 'layer4.1.bn1'],\n",
    "                   ['layer4.1.conv2', 'layer4.1.bn2'],\n",
    "                   ['layer4.1.conv3', 'layer4.1.bn3'],\n",
    "                   ['layer4.2.conv1', 'layer4.2.bn1'],\n",
    "                   ['layer4.2.conv2', 'layer4.2.bn2'],\n",
    "                   ['layer4.2.conv3', 'layer4.2.bn3'],\n",
    "                  ]\n",
    "            \n",
    "        \n",
    "        # torch.backends.quantized.engine = 'qnnpack'\n",
    "        model = torch.quantization.fuse_modules(model, modules_to_fuse_old)\n",
    "        if False:\n",
    "            if fbgemm:\n",
    "                model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "            else:\n",
    "                model.qconfig = torch.quantization.default_qconfig\n",
    "        model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "        \n",
    "        torch.quantization.prepare(model, inplace=True)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data, target in train_loader:\n",
    "                model(data)\n",
    "        torch.quantization.convert(model, inplace=True)\n",
    "\n",
    "    print(model)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    index = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            index += 1\n",
    "            print(index, datetime.now())\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            st = time.time()\n",
    "            output = model(data)\n",
    "            et = time.time()\n",
    "            test_loss += F.nll_loss(F.log_softmax(output, dim=-1), target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    print(\"========================================= PERFORMANCE =============================================\")\n",
    "    print_size_of_model(model)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    print('Elapsed time = {:0.4f} milliseconds'.format((et - st) * 1000))\n",
    "    print(\"====================================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline performance - unquantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "encoder_18 = ResNet(num_classes=10, mnist=True)\n",
    "loaded_dict_enc_18 = torch.load('mnist_cnn_18.pt', map_location=device)\n",
    "encoder_18.load_state_dict(loaded_dict_enc_18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (quant): QuantStub()\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "  (quant): QuantStub()\n",
      "  (dequant): DeQuantStub()\n",
      ")\n",
      "1 2020-10-07 23:21:40.779250\n",
      "2 2020-10-07 23:21:40.911798\n",
      "3 2020-10-07 23:21:41.045470\n",
      "4 2020-10-07 23:21:41.151527\n",
      "5 2020-10-07 23:21:41.263167\n",
      "6 2020-10-07 23:21:41.366381\n",
      "7 2020-10-07 23:21:41.456815\n",
      "8 2020-10-07 23:21:41.568145\n",
      "9 2020-10-07 23:21:41.665156\n",
      "10 2020-10-07 23:21:41.754191\n",
      "11 2020-10-07 23:21:41.856064\n",
      "12 2020-10-07 23:21:41.945697\n",
      "13 2020-10-07 23:21:42.056372\n",
      "14 2020-10-07 23:21:42.195620\n",
      "15 2020-10-07 23:21:42.333956\n",
      "16 2020-10-07 23:21:42.474335\n",
      "17 2020-10-07 23:21:42.629481\n",
      "18 2020-10-07 23:21:42.776468\n",
      "19 2020-10-07 23:21:42.909733\n",
      "20 2020-10-07 23:21:43.040024\n",
      "21 2020-10-07 23:21:43.144206\n",
      "22 2020-10-07 23:21:43.256247\n",
      "23 2020-10-07 23:21:43.377520\n",
      "24 2020-10-07 23:21:43.509801\n",
      "25 2020-10-07 23:21:43.632328\n",
      "26 2020-10-07 23:21:43.726765\n",
      "27 2020-10-07 23:21:43.826185\n",
      "28 2020-10-07 23:21:43.913939\n",
      "29 2020-10-07 23:21:44.009578\n",
      "30 2020-10-07 23:21:44.099838\n",
      "31 2020-10-07 23:21:44.196751\n",
      "32 2020-10-07 23:21:44.303386\n",
      "33 2020-10-07 23:21:44.414410\n",
      "34 2020-10-07 23:21:44.507036\n",
      "35 2020-10-07 23:21:44.617112\n",
      "36 2020-10-07 23:21:44.711271\n",
      "37 2020-10-07 23:21:44.816516\n",
      "38 2020-10-07 23:21:44.908343\n",
      "39 2020-10-07 23:21:45.008095\n",
      "40 2020-10-07 23:21:45.105078\n",
      "41 2020-10-07 23:21:45.205193\n",
      "42 2020-10-07 23:21:45.311581\n",
      "43 2020-10-07 23:21:45.405245\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-bd7c5fe79321>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-84-9b2d06a6a8af>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, device, test_loader, quantize, fbgemm, is_resnet18)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0met\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mtest_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# sum up batch loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zhao/teaching/samhitha.m-ML/resnet18/.venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-c1dc31d90f3f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m          \u001b[0;31m# See note [TorchScript super()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-77-c1dc31d90f3f>\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zhao/teaching/samhitha.m-ML/resnet18/.venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zhao/teaching/samhitha.m-ML/resnet18/.venv/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zhao/teaching/samhitha.m-ML/resnet18/.venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-eedc89d777c3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zhao/teaching/samhitha.m-ML/resnet18/.venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zhao/teaching/samhitha.m-ML/resnet18/.venv/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zhao/teaching/samhitha.m-ML/resnet18/.venv/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    414\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    415\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 416\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test(model=encoder_18, device=device, test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): QuantizedConv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.04729284346103668, zero_point=63, padding=(3, 3))\n",
      "  (bn1): Identity()\n",
      "  (relu): QuantizedReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.04037606343626976, zero_point=62, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.03831411153078079, zero_point=65, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.055642880499362946, zero_point=41\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.04435184225440025, zero_point=64, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.038252364844083786, zero_point=63, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.06237425282597542, zero_point=37\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.0444956012070179, zero_point=66, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.03921739384531975, zero_point=64, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), scale=0.04838153347373009, zero_point=62)\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.06858699768781662, zero_point=61\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.040807925164699554, zero_point=63, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.036044422537088394, zero_point=64, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.06170748174190521, zero_point=40\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.038887251168489456, zero_point=63, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.029516087844967842, zero_point=64, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), scale=0.042222559452056885, zero_point=62)\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.05087238550186157, zero_point=63\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.03349798172712326, zero_point=65, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.028838559985160828, zero_point=64, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.04654031991958618, zero_point=42\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.030074018985033035, zero_point=63, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.01841810904443264, zero_point=66, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.03314417600631714, zero_point=63)\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.03986053913831711, zero_point=65\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.0221925787627697, zero_point=63, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.014759093523025513, zero_point=65, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.02788480930030346, zero_point=31\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): QuantizedLinear(in_features=512, out_features=10, scale=0.02214696630835533, zero_point=45, qscheme=torch.per_channel_affine)\n",
      "  (quant): Quantize(scale=tensor([0.0255]), zero_point=tensor([17]), dtype=torch.quint8)\n",
      "  (dequant): DeQuantize()\n",
      ")\n",
      "1 2020-10-07 23:23:50.419796\n",
      "2 2020-10-07 23:23:50.470178\n",
      "3 2020-10-07 23:23:50.513824\n",
      "4 2020-10-07 23:23:50.553690\n",
      "5 2020-10-07 23:23:50.597000\n",
      "6 2020-10-07 23:23:50.640120\n",
      "7 2020-10-07 23:23:50.685478\n",
      "8 2020-10-07 23:23:50.728038\n",
      "9 2020-10-07 23:23:50.766943\n",
      "10 2020-10-07 23:23:50.807098\n",
      "11 2020-10-07 23:23:50.850854\n",
      "12 2020-10-07 23:23:50.894184\n",
      "13 2020-10-07 23:23:50.936027\n",
      "14 2020-10-07 23:23:50.976789\n",
      "15 2020-10-07 23:23:51.015866\n",
      "16 2020-10-07 23:23:51.056727\n",
      "17 2020-10-07 23:23:51.102409\n",
      "18 2020-10-07 23:23:51.147624\n",
      "19 2020-10-07 23:23:51.187735\n",
      "20 2020-10-07 23:23:51.228397\n",
      "21 2020-10-07 23:23:51.267757\n",
      "22 2020-10-07 23:23:51.311316\n",
      "23 2020-10-07 23:23:51.354310\n",
      "24 2020-10-07 23:23:51.393306\n",
      "25 2020-10-07 23:23:51.431398\n",
      "26 2020-10-07 23:23:51.470941\n",
      "27 2020-10-07 23:23:51.514752\n",
      "28 2020-10-07 23:23:51.559847\n",
      "29 2020-10-07 23:23:51.600062\n",
      "30 2020-10-07 23:23:51.639105\n",
      "31 2020-10-07 23:23:51.682814\n",
      "32 2020-10-07 23:23:51.723619\n",
      "33 2020-10-07 23:23:51.765454\n",
      "34 2020-10-07 23:23:51.808339\n",
      "35 2020-10-07 23:23:51.847412\n",
      "36 2020-10-07 23:23:51.887786\n",
      "37 2020-10-07 23:23:51.928777\n",
      "38 2020-10-07 23:23:51.973584\n",
      "39 2020-10-07 23:23:52.016117\n",
      "40 2020-10-07 23:23:52.054606\n",
      "41 2020-10-07 23:23:52.093491\n",
      "42 2020-10-07 23:23:52.134098\n",
      "43 2020-10-07 23:23:52.177883\n",
      "44 2020-10-07 23:23:52.223964\n",
      "45 2020-10-07 23:23:52.269659\n",
      "46 2020-10-07 23:23:52.309097\n",
      "47 2020-10-07 23:23:52.348637\n",
      "48 2020-10-07 23:23:52.391251\n",
      "49 2020-10-07 23:23:52.433337\n",
      "50 2020-10-07 23:23:52.473526\n",
      "51 2020-10-07 23:23:52.512545\n",
      "52 2020-10-07 23:23:52.553202\n",
      "53 2020-10-07 23:23:52.598784\n",
      "54 2020-10-07 23:23:52.639740\n",
      "55 2020-10-07 23:23:52.682869\n",
      "56 2020-10-07 23:23:52.722106\n",
      "57 2020-10-07 23:23:52.766491\n",
      "58 2020-10-07 23:23:52.810752\n",
      "59 2020-10-07 23:23:52.852829\n",
      "60 2020-10-07 23:23:52.893333\n",
      "61 2020-10-07 23:23:52.931012\n",
      "62 2020-10-07 23:23:52.972224\n",
      "63 2020-10-07 23:23:53.014263\n",
      "64 2020-10-07 23:23:53.053912\n",
      "65 2020-10-07 23:23:53.094804\n",
      "66 2020-10-07 23:23:53.135005\n",
      "67 2020-10-07 23:23:53.175427\n",
      "68 2020-10-07 23:23:53.216784\n",
      "69 2020-10-07 23:23:53.260525\n",
      "70 2020-10-07 23:23:53.300219\n",
      "71 2020-10-07 23:23:53.342390\n",
      "72 2020-10-07 23:23:53.382055\n",
      "73 2020-10-07 23:23:53.423882\n",
      "74 2020-10-07 23:23:53.464732\n",
      "75 2020-10-07 23:23:53.504158\n",
      "76 2020-10-07 23:23:53.545547\n",
      "77 2020-10-07 23:23:53.585388\n",
      "78 2020-10-07 23:23:53.629854\n",
      "79 2020-10-07 23:23:53.673185\n",
      "80 2020-10-07 23:23:53.715387\n",
      "81 2020-10-07 23:23:53.761923\n",
      "82 2020-10-07 23:23:53.808016\n",
      "83 2020-10-07 23:23:53.853027\n",
      "84 2020-10-07 23:23:53.896260\n",
      "85 2020-10-07 23:23:53.938212\n",
      "86 2020-10-07 23:23:53.982724\n",
      "87 2020-10-07 23:23:54.023335\n",
      "88 2020-10-07 23:23:54.067619\n",
      "89 2020-10-07 23:23:54.109311\n",
      "90 2020-10-07 23:23:54.148381\n",
      "91 2020-10-07 23:23:54.193094\n",
      "92 2020-10-07 23:23:54.234507\n",
      "93 2020-10-07 23:23:54.280029\n",
      "94 2020-10-07 23:23:54.331134\n",
      "95 2020-10-07 23:23:54.372707\n",
      "96 2020-10-07 23:23:54.417191\n",
      "97 2020-10-07 23:23:54.459591\n",
      "98 2020-10-07 23:23:54.505126\n",
      "99 2020-10-07 23:23:54.547051\n",
      "100 2020-10-07 23:23:54.591304\n",
      "101 2020-10-07 23:23:54.633958\n",
      "102 2020-10-07 23:23:54.676598\n",
      "103 2020-10-07 23:23:54.718935\n",
      "104 2020-10-07 23:23:54.760106\n",
      "105 2020-10-07 23:23:54.799433\n",
      "106 2020-10-07 23:23:54.842127\n",
      "107 2020-10-07 23:23:54.891366\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-9c5ec681773d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloaded_dict_enc_18_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mnist_cnn_18.pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mencoder_18_q\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_dict_enc_18_q\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_18_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_resnet18\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-84-9b2d06a6a8af>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, device, test_loader, quantize, fbgemm, is_resnet18)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0met\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mtest_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# sum up batch loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zhao/teaching/samhitha.m-ML/resnet18/.venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-c1dc31d90f3f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m          \u001b[0;31m# See note [TorchScript super()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-77-c1dc31d90f3f>\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zhao/teaching/samhitha.m-ML/resnet18/.venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zhao/teaching/samhitha.m-ML/resnet18/.venv/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zhao/teaching/samhitha.m-ML/resnet18/.venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-eedc89d777c3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zhao/teaching/samhitha.m-ML/resnet18/.venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zhao/teaching/samhitha.m-ML/resnet18/.venv/lib/python3.7/site-packages/torch/nn/quantized/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input shape must be `(N, C, H, W)`!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         return ops.quantized.conv2d(\n\u001b[0;32m--> 327\u001b[0;31m             input, self._packed_params, self.scale, self.zero_point)\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "encoder_18_q = ResNet(num_classes=10, mnist=True, quantize=True)\n",
    "loaded_dict_enc_18_q = torch.load('mnist_cnn_18.pt', map_location=device)\n",
    "encoder_18_q.load_state_dict(loaded_dict_enc_18_q)\n",
    "test(model=encoder_18_q, device=device, test_loader=test_loader, quantize=True, is_resnet18=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16/40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "encoder_50 = ResNet(block=Bottleneck, layers=[3, 4, 6, 3], num_classes=10, mnist=True).to(device)\n",
    "loaded_dict_enc_50 = torch.load('mnist_cnn.pt', map_location=device)\n",
    "encoder_50.load_state_dict(loaded_dict_enc_50)\n",
    "test(model=encoder_50, device=device, test_loader=test_loader, quantize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_50.load_state_dict(loaded_dict_enc_50)\n",
    "test(model=encoder_50, device=device, test_loader=test_loader, quantize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64, 1, 1])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_dict_enc_50['layer1.0.conv1.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64, 3, 3])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_dict_enc_18['layer1.0.conv1.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
      "  (quant): QuantStub()\n",
      "  (dequant): DeQuantStub()\n",
      ")\n",
      "1 2020-10-07 22:43:53.056229\n",
      "2 2020-10-07 22:43:53.352627\n",
      "3 2020-10-07 22:43:53.577447\n",
      "4 2020-10-07 22:43:53.817738\n",
      "5 2020-10-07 22:43:54.058382\n",
      "6 2020-10-07 22:43:54.278033\n",
      "7 2020-10-07 22:43:54.584945\n",
      "8 2020-10-07 22:43:54.950292\n",
      "9 2020-10-07 22:43:55.395882\n",
      "10 2020-10-07 22:43:55.753235\n",
      "11 2020-10-07 22:43:56.101602\n",
      "12 2020-10-07 22:43:56.347886\n",
      "13 2020-10-07 22:43:56.567373\n",
      "14 2020-10-07 22:43:56.800846\n",
      "15 2020-10-07 22:43:57.054901\n",
      "16 2020-10-07 22:43:57.305871\n",
      "17 2020-10-07 22:43:57.533575\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-e3c1c3cf65ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-84-9b2d06a6a8af>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, device, test_loader, quantize, fbgemm, is_resnet18)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0met\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mtest_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# sum up batch loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zhao/teaching/samhitha.m-ML/resnet18/.venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-c1dc31d90f3f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m          \u001b[0;31m# See note [TorchScript super()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-77-c1dc31d90f3f>\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zhao/teaching/samhitha.m-ML/resnet18/.venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zhao/teaching/samhitha.m-ML/resnet18/.venv/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zhao/teaching/samhitha.m-ML/resnet18/.venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-74-ded951ee7b1a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zhao/teaching/samhitha.m-ML/resnet18/.venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zhao/teaching/samhitha.m-ML/resnet18/.venv/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zhao/teaching/samhitha.m-ML/resnet18/.venv/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    414\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    415\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 416\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test(model=encoder_50, device=device, test_loader=test_loader, quantize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device='QuantizedCPU'\n",
    "device='cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected one of cpu, cuda, mkldnn, opengl, opencl, ideep, hip, msnpu, xla device type at start of device string: QuantizedCPU",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-8c18736a9dfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-84-9b2d06a6a8af>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, device, test_loader, quantize, fbgemm, is_resnet18)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfbgemm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_resnet18\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Testing with qauntization if quantize=True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zhao/teaching/samhitha.m-ML/resnet18/.venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \"\"\"\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected one of cpu, cuda, mkldnn, opengl, opencl, ideep, hip, msnpu, xla device type at start of device string: QuantizedCPU"
     ]
    }
   ],
   "source": [
    "test(model=encoder_50, device=device, test_loader=test_loader, quantize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): QuantizedConv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.19572661817073822, zero_point=64, padding=(3, 3))\n",
      "  (bn1): Identity()\n",
      "  (relu): QuantizedReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): QuantizedConv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.2408016473054886, zero_point=65)\n",
      "      (bn1): Identity()\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.4672405421733856, zero_point=56, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (conv3): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.32880401611328125, zero_point=63)\n",
      "      (bn3): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.23247092962265015, zero_point=56, bias=False)\n",
      "        (1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.38974183797836304, zero_point=61\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): QuantizedConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.507291316986084, zero_point=62)\n",
      "      (bn1): Identity()\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.6640175580978394, zero_point=56, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (conv3): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.47811785340309143, zero_point=69)\n",
      "      (bn3): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.576708972454071, zero_point=54\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): QuantizedConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.6864748001098633, zero_point=50)\n",
      "      (bn1): Identity()\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.6693383455276489, zero_point=75, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (conv3): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.3501329720020294, zero_point=67)\n",
      "      (bn3): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.6190357804298401, zero_point=40\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): QuantizedConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.7530050873756409, zero_point=69)\n",
      "      (bn1): Identity()\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.6997142434120178, zero_point=64, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.4321572780609131, zero_point=67)\n",
      "      (bn3): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.5563632249832153, zero_point=60)\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.7918553352355957, zero_point=62\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): QuantizedConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.7656791806221008, zero_point=65)\n",
      "      (bn1): Identity()\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.8576056957244873, zero_point=60, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.4224599003791809, zero_point=60)\n",
      "      (bn3): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.6006275415420532, zero_point=42\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): QuantizedConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.8887540698051453, zero_point=65)\n",
      "      (bn1): Identity()\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.9080728888511658, zero_point=70, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.5239740610122681, zero_point=59)\n",
      "      (bn3): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.7154859304428101, zero_point=41\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): QuantizedConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.8993530869483948, zero_point=60)\n",
      "      (bn1): Identity()\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.8589048981666565, zero_point=67, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.4964483380317688, zero_point=62)\n",
      "      (bn3): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.7992713451385498, zero_point=39\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): QuantizedConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.8800479173660278, zero_point=64)\n",
      "      (bn1): Identity()\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.8275938630104065, zero_point=65, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.5025440454483032, zero_point=61)\n",
      "      (bn3): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), scale=0.7108467817306519, zero_point=63)\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.891241729259491, zero_point=66\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): QuantizedConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=1.0232810974121094, zero_point=65)\n",
      "      (bn1): Identity()\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.6046429872512817, zero_point=66, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.42297470569610596, zero_point=65)\n",
      "      (bn3): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.7323954701423645, zero_point=35\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): QuantizedConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=1.0017608404159546, zero_point=66)\n",
      "      (bn1): Identity()\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.6788051724433899, zero_point=61, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.4440208077430725, zero_point=62)\n",
      "      (bn3): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.8253757357597351, zero_point=35\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): QuantizedConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.9952347278594971, zero_point=72)\n",
      "      (bn1): Identity()\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.727326512336731, zero_point=60, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.39480334520339966, zero_point=67)\n",
      "      (bn3): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.8774777054786682, zero_point=32\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): QuantizedConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.9767634868621826, zero_point=59)\n",
      "      (bn1): Identity()\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.705143392086029, zero_point=62, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.45158150792121887, zero_point=61)\n",
      "      (bn3): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.9280601143836975, zero_point=28\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): QuantizedConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.9422093033790588, zero_point=60)\n",
      "      (bn1): Identity()\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.7523490786552429, zero_point=65, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.4570598304271698, zero_point=61)\n",
      "      (bn3): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.9550148248672485, zero_point=28\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): QuantizedConv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.9228903651237488, zero_point=61)\n",
      "      (bn1): Identity()\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.6218914985656738, zero_point=65, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (conv3): QuantizedConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), scale=0.38836464285850525, zero_point=63)\n",
      "      (bn3): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), scale=0.6921164393424988, zero_point=60)\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.8138757944107056, zero_point=62\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): QuantizedConv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.8822686076164246, zero_point=63)\n",
      "      (bn1): Identity()\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.3940160572528839, zero_point=66, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (conv3): QuantizedConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), scale=0.24863019585609436, zero_point=60)\n",
      "      (bn3): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.5650231242179871, zero_point=27\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): QuantizedConv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.960550844669342, zero_point=64)\n",
      "      (bn1): Identity()\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.37123847007751465, zero_point=64, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (conv3): QuantizedConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), scale=0.2212984561920166, zero_point=63)\n",
      "      (bn3): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.5484374761581421, zero_point=22\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): QuantizedLinear(in_features=2048, out_features=10, scale=0.4057939648628235, zero_point=50, qscheme=torch.per_channel_affine)\n",
      "  (quant): Quantize(scale=tensor([0.0255]), zero_point=tensor([17]), dtype=torch.quint8)\n",
      "  (dequant): DeQuantize()\n",
      ")\n",
      "1 2020-10-07 23:36:47.345171\n",
      "2 2020-10-07 23:36:47.439003\n",
      "3 2020-10-07 23:36:47.522706\n",
      "4 2020-10-07 23:36:47.607788\n",
      "5 2020-10-07 23:36:47.695182\n",
      "6 2020-10-07 23:36:47.775396\n",
      "7 2020-10-07 23:36:47.857490\n",
      "8 2020-10-07 23:36:47.940305\n",
      "9 2020-10-07 23:36:48.022350\n",
      "10 2020-10-07 23:36:48.104606\n",
      "11 2020-10-07 23:36:48.187773\n",
      "12 2020-10-07 23:36:48.267326\n",
      "13 2020-10-07 23:36:48.349060\n",
      "14 2020-10-07 23:36:48.433320\n",
      "15 2020-10-07 23:36:48.520897\n",
      "16 2020-10-07 23:36:48.604010\n",
      "17 2020-10-07 23:36:48.684420\n",
      "18 2020-10-07 23:36:48.765621\n",
      "19 2020-10-07 23:36:48.848705\n",
      "20 2020-10-07 23:36:48.932078\n",
      "21 2020-10-07 23:36:49.017274\n",
      "22 2020-10-07 23:36:49.100010\n",
      "23 2020-10-07 23:36:49.181836\n",
      "24 2020-10-07 23:36:49.262467\n",
      "25 2020-10-07 23:36:49.345828\n",
      "26 2020-10-07 23:36:49.426738\n",
      "27 2020-10-07 23:36:49.507735\n",
      "28 2020-10-07 23:36:49.588590\n",
      "29 2020-10-07 23:36:49.672797\n",
      "30 2020-10-07 23:36:49.757454\n",
      "31 2020-10-07 23:36:49.845578\n",
      "32 2020-10-07 23:36:49.930939\n",
      "33 2020-10-07 23:36:50.017434\n",
      "34 2020-10-07 23:36:50.105639\n",
      "35 2020-10-07 23:36:50.189496\n",
      "36 2020-10-07 23:36:50.272237\n",
      "37 2020-10-07 23:36:50.355462\n",
      "38 2020-10-07 23:36:50.444117\n",
      "39 2020-10-07 23:36:50.526937\n",
      "40 2020-10-07 23:36:50.617193\n",
      "41 2020-10-07 23:36:50.703513\n",
      "42 2020-10-07 23:36:50.782961\n",
      "43 2020-10-07 23:36:50.864911\n",
      "44 2020-10-07 23:36:50.944945\n",
      "45 2020-10-07 23:36:51.024360\n",
      "46 2020-10-07 23:36:51.102182\n",
      "47 2020-10-07 23:36:51.180704\n",
      "48 2020-10-07 23:36:51.256820\n",
      "49 2020-10-07 23:36:51.334456\n",
      "50 2020-10-07 23:36:51.411744\n",
      "51 2020-10-07 23:36:51.490493\n",
      "52 2020-10-07 23:36:51.570572\n",
      "53 2020-10-07 23:36:51.657113\n",
      "54 2020-10-07 23:36:51.739177\n",
      "55 2020-10-07 23:36:51.825114\n",
      "56 2020-10-07 23:36:51.904839\n",
      "57 2020-10-07 23:36:51.988749\n",
      "58 2020-10-07 23:36:52.073151\n",
      "59 2020-10-07 23:36:52.155192\n",
      "60 2020-10-07 23:36:52.234990\n",
      "61 2020-10-07 23:36:52.317649\n",
      "62 2020-10-07 23:36:52.397920\n",
      "63 2020-10-07 23:36:52.476904\n",
      "64 2020-10-07 23:36:52.558324\n",
      "65 2020-10-07 23:36:52.638012\n",
      "66 2020-10-07 23:36:52.718234\n",
      "67 2020-10-07 23:36:52.801787\n",
      "68 2020-10-07 23:36:52.884471\n",
      "69 2020-10-07 23:36:52.965320\n",
      "70 2020-10-07 23:36:53.048529\n",
      "71 2020-10-07 23:36:53.128351\n",
      "72 2020-10-07 23:36:53.208291\n",
      "73 2020-10-07 23:36:53.294144\n",
      "74 2020-10-07 23:36:53.373809\n",
      "75 2020-10-07 23:36:53.452258\n",
      "76 2020-10-07 23:36:53.534016\n",
      "77 2020-10-07 23:36:53.617271\n",
      "78 2020-10-07 23:36:53.697415\n",
      "79 2020-10-07 23:36:53.779347\n",
      "80 2020-10-07 23:36:53.862565\n",
      "81 2020-10-07 23:36:53.945176\n",
      "82 2020-10-07 23:36:54.029330\n",
      "83 2020-10-07 23:36:54.109788\n",
      "84 2020-10-07 23:36:54.192118\n",
      "85 2020-10-07 23:36:54.275955\n",
      "86 2020-10-07 23:36:54.376902\n",
      "87 2020-10-07 23:36:54.464514\n",
      "88 2020-10-07 23:36:54.552091\n",
      "89 2020-10-07 23:36:54.637158\n",
      "90 2020-10-07 23:36:54.722696\n",
      "91 2020-10-07 23:36:54.807485\n",
      "92 2020-10-07 23:36:54.895745\n",
      "93 2020-10-07 23:36:54.987018\n",
      "94 2020-10-07 23:36:55.078360\n",
      "95 2020-10-07 23:36:55.168208\n",
      "96 2020-10-07 23:36:55.255208\n",
      "97 2020-10-07 23:36:55.342594\n",
      "98 2020-10-07 23:36:55.432433\n",
      "99 2020-10-07 23:36:55.523244\n",
      "100 2020-10-07 23:36:55.610633\n",
      "101 2020-10-07 23:36:55.689867\n",
      "102 2020-10-07 23:36:55.769629\n",
      "103 2020-10-07 23:36:55.854082\n",
      "104 2020-10-07 23:36:55.937091\n",
      "105 2020-10-07 23:36:56.025257\n",
      "106 2020-10-07 23:36:56.111776\n",
      "107 2020-10-07 23:36:56.197280\n",
      "108 2020-10-07 23:36:56.287024\n",
      "109 2020-10-07 23:36:56.374723\n",
      "110 2020-10-07 23:36:56.459679\n",
      "111 2020-10-07 23:36:56.542623\n",
      "112 2020-10-07 23:36:56.627159\n",
      "113 2020-10-07 23:36:56.706863\n",
      "114 2020-10-07 23:36:56.787198\n",
      "115 2020-10-07 23:36:56.868142\n",
      "116 2020-10-07 23:36:56.950152\n",
      "117 2020-10-07 23:36:57.031174\n",
      "118 2020-10-07 23:36:57.113120\n",
      "119 2020-10-07 23:36:57.193444\n",
      "120 2020-10-07 23:36:57.272464\n",
      "121 2020-10-07 23:36:57.353340\n",
      "122 2020-10-07 23:36:57.433016\n",
      "123 2020-10-07 23:36:57.512263\n",
      "124 2020-10-07 23:36:57.597526\n",
      "125 2020-10-07 23:36:57.681998\n",
      "126 2020-10-07 23:36:57.762399\n",
      "127 2020-10-07 23:36:57.847533\n",
      "128 2020-10-07 23:36:57.928544\n",
      "129 2020-10-07 23:36:58.008618\n",
      "130 2020-10-07 23:36:58.091152\n",
      "131 2020-10-07 23:36:58.175419\n",
      "132 2020-10-07 23:36:58.260209\n",
      "133 2020-10-07 23:36:58.346428\n",
      "134 2020-10-07 23:36:58.428457\n",
      "135 2020-10-07 23:36:58.506911\n",
      "136 2020-10-07 23:36:58.590161\n",
      "137 2020-10-07 23:36:58.673315\n",
      "138 2020-10-07 23:36:58.759511\n",
      "139 2020-10-07 23:36:58.843494\n",
      "140 2020-10-07 23:36:58.923196\n",
      "141 2020-10-07 23:36:59.005885\n",
      "142 2020-10-07 23:36:59.088847\n",
      "143 2020-10-07 23:36:59.171129\n",
      "144 2020-10-07 23:36:59.251464\n",
      "145 2020-10-07 23:36:59.335779\n",
      "146 2020-10-07 23:36:59.416619\n",
      "147 2020-10-07 23:36:59.495948\n",
      "148 2020-10-07 23:36:59.577502\n",
      "149 2020-10-07 23:36:59.658646\n",
      "150 2020-10-07 23:36:59.762610\n",
      "151 2020-10-07 23:36:59.848330\n",
      "152 2020-10-07 23:36:59.928083\n",
      "153 2020-10-07 23:37:00.010826\n",
      "154 2020-10-07 23:37:00.094042\n",
      "155 2020-10-07 23:37:00.174346\n",
      "156 2020-10-07 23:37:00.257514\n",
      "157 2020-10-07 23:37:00.343184\n",
      "========================================= PERFORMANCE =============================================\n",
      "Size of the model(MB): 24.122451\n",
      "\n",
      "Test set: Average loss: 18.4112, Accuracy: 980/10000 (10%)\n",
      "\n",
      "Elapsed time = 25.1782 milliseconds\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "# encoder_50 = ResNet(block=Bottleneck, layers=[3, 4, 6, 3], num_classes=10, mnist=True).to(device)\n",
    "encoder_50_q = ResNet(block=Bottleneck, layers=[3, 4, 6, 3], num_classes=10, mnist=True, quantize=True)\n",
    "loaded_dict_enc_50_q = torch.load('mnist_cnn.pt', map_location=device)\n",
    "encoder_50_q.load_state_dict(loaded_dict_enc_50_q)\n",
    "test(model=encoder_50_q, device=device, test_loader=test_loader, quantize=True, is_resnet18=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
      "  (quant): QuantStub()\n",
      "  (dequant): DeQuantStub()\n",
      ")\n",
      "1 2020-10-07 23:56:16.870996\n",
      "2 2020-10-07 23:56:17.148944\n",
      "3 2020-10-07 23:56:17.368587\n",
      "4 2020-10-07 23:56:17.645670\n",
      "5 2020-10-07 23:56:17.874955\n",
      "6 2020-10-07 23:56:18.108844\n",
      "7 2020-10-07 23:56:18.336664\n",
      "8 2020-10-07 23:56:18.580872\n",
      "9 2020-10-07 23:56:18.808169\n",
      "10 2020-10-07 23:56:19.047447\n",
      "11 2020-10-07 23:56:19.290590\n",
      "12 2020-10-07 23:56:19.523361\n",
      "13 2020-10-07 23:56:19.766218\n",
      "14 2020-10-07 23:56:20.003595\n",
      "15 2020-10-07 23:56:20.231779\n",
      "16 2020-10-07 23:56:20.465781\n",
      "17 2020-10-07 23:56:20.720536\n",
      "18 2020-10-07 23:56:20.982034\n",
      "19 2020-10-07 23:56:21.221792\n",
      "20 2020-10-07 23:56:21.468070\n",
      "21 2020-10-07 23:56:21.702856\n",
      "22 2020-10-07 23:56:21.991077\n",
      "23 2020-10-07 23:56:22.295406\n",
      "24 2020-10-07 23:56:22.617708\n",
      "25 2020-10-07 23:56:22.864320\n",
      "26 2020-10-07 23:56:23.098932\n",
      "27 2020-10-07 23:56:23.358169\n",
      "28 2020-10-07 23:56:23.627996\n",
      "29 2020-10-07 23:56:23.851690\n",
      "30 2020-10-07 23:56:24.075422\n",
      "31 2020-10-07 23:56:24.339191\n",
      "32 2020-10-07 23:56:24.565052\n",
      "33 2020-10-07 23:56:24.844625\n",
      "34 2020-10-07 23:56:25.146511\n",
      "35 2020-10-07 23:56:25.472515\n",
      "36 2020-10-07 23:56:25.784434\n",
      "37 2020-10-07 23:56:26.094617\n",
      "38 2020-10-07 23:56:26.398235\n",
      "39 2020-10-07 23:56:26.651073\n",
      "40 2020-10-07 23:56:26.881262\n",
      "41 2020-10-07 23:56:27.138650\n",
      "42 2020-10-07 23:56:27.450189\n",
      "43 2020-10-07 23:56:27.795110\n",
      "44 2020-10-07 23:56:28.118065\n",
      "45 2020-10-07 23:56:28.379761\n",
      "46 2020-10-07 23:56:28.663247\n",
      "47 2020-10-07 23:56:28.926250\n",
      "48 2020-10-07 23:56:29.159912\n",
      "49 2020-10-07 23:56:29.467966\n",
      "50 2020-10-07 23:56:29.793998\n",
      "51 2020-10-07 23:56:30.107874\n",
      "52 2020-10-07 23:56:30.423373\n",
      "53 2020-10-07 23:56:30.758983\n",
      "54 2020-10-07 23:56:31.043069\n",
      "55 2020-10-07 23:56:31.285297\n",
      "56 2020-10-07 23:56:31.584960\n",
      "57 2020-10-07 23:56:31.859822\n",
      "58 2020-10-07 23:56:32.102839\n",
      "59 2020-10-07 23:56:32.353448\n",
      "60 2020-10-07 23:56:32.629614\n",
      "61 2020-10-07 23:56:32.858326\n",
      "62 2020-10-07 23:56:33.092919\n",
      "63 2020-10-07 23:56:33.349455\n",
      "64 2020-10-07 23:56:33.574193\n",
      "65 2020-10-07 23:56:33.862092\n",
      "66 2020-10-07 23:56:34.106860\n",
      "67 2020-10-07 23:56:34.385173\n",
      "68 2020-10-07 23:56:34.691376\n",
      "69 2020-10-07 23:56:34.991727\n",
      "70 2020-10-07 23:56:35.219274\n",
      "71 2020-10-07 23:56:35.514646\n",
      "72 2020-10-07 23:56:35.836682\n",
      "73 2020-10-07 23:56:36.076024\n",
      "74 2020-10-07 23:56:36.318687\n",
      "75 2020-10-07 23:56:36.577855\n",
      "76 2020-10-07 23:56:36.810716\n",
      "77 2020-10-07 23:56:37.040089\n",
      "78 2020-10-07 23:56:37.270305\n",
      "79 2020-10-07 23:56:37.517597\n",
      "80 2020-10-07 23:56:37.754492\n",
      "81 2020-10-07 23:56:37.998709\n",
      "82 2020-10-07 23:56:38.228677\n",
      "83 2020-10-07 23:56:38.476108\n",
      "84 2020-10-07 23:56:38.710399\n",
      "85 2020-10-07 23:56:38.926350\n",
      "86 2020-10-07 23:56:39.159996\n",
      "87 2020-10-07 23:56:39.402965\n",
      "88 2020-10-07 23:56:39.651406\n",
      "89 2020-10-07 23:56:39.903473\n",
      "90 2020-10-07 23:56:40.142621\n",
      "91 2020-10-07 23:56:40.379913\n",
      "92 2020-10-07 23:56:40.633222\n",
      "93 2020-10-07 23:56:40.878504\n",
      "94 2020-10-07 23:56:41.115413\n",
      "95 2020-10-07 23:56:41.351039\n",
      "96 2020-10-07 23:56:41.581631\n",
      "97 2020-10-07 23:56:41.816286\n",
      "98 2020-10-07 23:56:42.054138\n",
      "99 2020-10-07 23:56:42.286783\n",
      "100 2020-10-07 23:56:42.521333\n",
      "101 2020-10-07 23:56:42.767446\n",
      "102 2020-10-07 23:56:43.000984\n",
      "103 2020-10-07 23:56:43.240702\n",
      "104 2020-10-07 23:56:43.469989\n",
      "105 2020-10-07 23:56:43.716170\n",
      "106 2020-10-07 23:56:43.948074\n",
      "107 2020-10-07 23:56:44.168815\n",
      "108 2020-10-07 23:56:44.401487\n",
      "109 2020-10-07 23:56:44.625424\n",
      "110 2020-10-07 23:56:44.851791\n",
      "111 2020-10-07 23:56:45.080752\n",
      "112 2020-10-07 23:56:45.317556\n",
      "113 2020-10-07 23:56:45.557057\n",
      "114 2020-10-07 23:56:45.790561\n",
      "115 2020-10-07 23:56:46.011013\n",
      "116 2020-10-07 23:56:46.250153\n",
      "117 2020-10-07 23:56:46.481914\n",
      "118 2020-10-07 23:56:46.706833\n",
      "119 2020-10-07 23:56:46.937349\n",
      "120 2020-10-07 23:56:47.169769\n",
      "121 2020-10-07 23:56:47.399010\n",
      "122 2020-10-07 23:56:47.625867\n",
      "123 2020-10-07 23:56:47.859426\n",
      "124 2020-10-07 23:56:48.087544\n",
      "125 2020-10-07 23:56:48.313996\n",
      "126 2020-10-07 23:56:48.543232\n",
      "127 2020-10-07 23:56:48.766681\n",
      "128 2020-10-07 23:56:48.994205\n",
      "129 2020-10-07 23:56:49.217683\n",
      "130 2020-10-07 23:56:49.455048\n",
      "131 2020-10-07 23:56:49.679189\n",
      "132 2020-10-07 23:56:49.901846\n",
      "133 2020-10-07 23:56:50.119980\n",
      "134 2020-10-07 23:56:50.345062\n",
      "135 2020-10-07 23:56:50.571151\n",
      "136 2020-10-07 23:56:50.801314\n",
      "137 2020-10-07 23:56:51.026133\n",
      "138 2020-10-07 23:56:51.255452\n",
      "139 2020-10-07 23:56:51.483472\n",
      "140 2020-10-07 23:56:51.706684\n",
      "141 2020-10-07 23:56:51.931679\n",
      "142 2020-10-07 23:56:52.145982\n",
      "143 2020-10-07 23:56:52.372455\n",
      "144 2020-10-07 23:56:52.600588\n",
      "145 2020-10-07 23:56:52.835873\n",
      "146 2020-10-07 23:56:53.086710\n",
      "147 2020-10-07 23:56:53.324946\n",
      "148 2020-10-07 23:56:53.572088\n",
      "149 2020-10-07 23:56:53.801615\n",
      "150 2020-10-07 23:56:54.036077\n",
      "151 2020-10-07 23:56:54.285068\n",
      "152 2020-10-07 23:56:54.520919\n",
      "153 2020-10-07 23:56:54.789717\n",
      "154 2020-10-07 23:56:55.025952\n",
      "155 2020-10-07 23:56:55.260099\n",
      "156 2020-10-07 23:56:55.505492\n",
      "157 2020-10-07 23:56:55.740674\n",
      "========================================= PERFORMANCE =============================================\n",
      "Size of the model(MB): 94.411311\n",
      "\n",
      "Test set: Average loss: 18.4902, Accuracy: 980/10000 (10%)\n",
      "\n",
      "Elapsed time = 95.4072 milliseconds\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "encoder_50 = ResNet(block=Bottleneck, layers=[3, 4, 6, 3], num_classes=10, mnist=True).to(device)\n",
    "loaded_dict_enc_50 = torch.load('mnist_cnn.pt', map_location=device)\n",
    "encoder_50.load_state_dict(loaded_dict_enc_50)\n",
    "test(model=encoder_50, device=device, test_loader=test_loader, quantize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
