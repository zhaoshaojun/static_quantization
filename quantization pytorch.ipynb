{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-training static quantization (Pytorch) - ResNet18\n",
    "In this notebook, you will be able to see how quantization in PyTorch can result in significant decreases in model size while increasing speed. Note that quantization is currently only supported for CPUs, so we will be utilizing GPUs / CUDA only for training and CPU for testing.\n",
    "Furthermore, while using complex dataset the accuracy might decrease upon quantization. By using a quantization configuration\n",
    "\n",
    "    model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "\n",
    "we can significantly improve on the accuracy. We repeat the same exercise with the recommended configuration for quantizing for x86 architectures. This configuration does the following:\n",
    "1. Quantizes weights on a per-channel basis\n",
    "2. Uses a histogram observer that collects a histogram of activations and then picks quantization parameters in an optimal manner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.utils.bottleneck as B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and visualize MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: ../data: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(torchvision.datasets.MNIST('../data', train=True, download=True,\n",
    "                                                    transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                    ])),\n",
    "               batch_size=64, shuffle=True, num_workers=1, pin_memory=True)\n",
    "\n",
    "test_loader = DataLoader(torchvision.datasets.MNIST('../data', train=False, \n",
    "                                                    transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                    ])),\n",
    "              batch_size=64, shuffle=True, num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "figure = plt.figure()\n",
    "num_of_images = 20\n",
    "for index in range(1, num_of_images + 1):\n",
    "    plt.subplot(6, 10, index)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet18 model\n",
    "This code is taken from https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py \n",
    "\n",
    "> NOTE: Training uses resnet model as is with addition operation and floating point inputs / outputs.      \n",
    "But when model is quantized while testing addition operation is replaced with FloatFunction and the inputs         / outputs are quantized/dequantized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\n",
    "    \n",
    "    Args:\n",
    "        in_planes: number of channels in input image\n",
    "        out_planes: number of channels produced by convolution\n",
    "        stride: stride of the convolution. Default: 1\n",
    "        groups: Number of blocked connections from input channels to output channels. Default: 1\n",
    "        dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n",
    "        \n",
    "    Returns:\n",
    "        Convoluted layer of kernel size=3, with specified out_planes\n",
    "    \n",
    "    \"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\n",
    "    \n",
    "    Args:\n",
    "        in_planes: number of channels in input image\n",
    "        out_planes: number of channels produced by convolution\n",
    "        stride: stride of the convolution. Default: 1\n",
    "        \n",
    "    Returns:\n",
    "        Convoluted layer of kernel size=1, with specified out_planes\n",
    "        \n",
    "    \"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n",
    "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
    "    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n",
    "    # This variant is also known as ResNet V1.5 and improves accuracy according to\n",
    "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
    "\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None, quantize=False):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.quantize = quantize\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation) # code for Bottleneck\n",
    "        # self.conv1 = conv3x3(inplanes, planes, stride) # code for BasicBlock\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        # Notice the addition operation in both scenarios\n",
    "        if self.quantize:\n",
    "            out = self.skip_add.add(out, identity)\n",
    "        else:\n",
    "            out += identity\n",
    "\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None, quantize=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.quantize = quantize\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride) # diff\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        # FloatFunction()\n",
    "        self.skip_add = nn.quantized.FloatFunctional()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        # Notice the addition operation in both scenarios\n",
    "        if self.quantize:\n",
    "            out = self.skip_add.add(out, identity)\n",
    "        else:\n",
    "            out += identity\n",
    "\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet18(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"ResNet-18 model from\n",
    "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress,\n",
    "                   **kwargs)\n",
    "\n",
    "\n",
    "def resnet34(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"ResNet-34 model from\n",
    "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet('resnet34', BasicBlock, [3, 4, 6, 3], pretrained, progress,\n",
    "                   **kwargs)\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"ResNet-50 model from\n",
    "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet('resnet50', Bottleneck, [3, 4, 6, 3], pretrained, progress,\n",
    "                   **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block=BasicBlock, layers=[2, 2, 2, 2], num_classes=1000, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None, mnist=False, quantize=False):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.quantize = quantize\n",
    "        if mnist:\n",
    "            num_channels = 1\n",
    "        else:\n",
    "            num_channels = 3\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace \n",
    "            # the 2x2 stride with a dilated convolution instead.\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(num_channels, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer, quantize=self.quantize))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer, quantize=self.quantize))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # Input are quantized\n",
    "        if self.quantize:\n",
    "            x = self.quant(x)\n",
    "    \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        # Outputs are dequantized\n",
    "        if self.quantize:\n",
    "            x = self.dequant(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "         # See note [TorchScript super()]\n",
    "        return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    \"\"\" Train the model with given dataset\n",
    "    \n",
    "    Args:\n",
    "        args: args like log interval\n",
    "        model: ResNet model to train\n",
    "        device: CPU/GPU\n",
    "        train_loader: dataset iterator\n",
    "        optimizer: optimizer to update weights\n",
    "        epoch: number of epochs to train for\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(F.log_softmax(output, dim=-1), target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % args[\"log_interval\"] == 0:\n",
    "            print('{} Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                datetime.now(),\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_18():\n",
    " \n",
    "    batch_size = 64\n",
    "    epochs = 5\n",
    "    lr = 0.01\n",
    "    momentum = 0.5\n",
    "    seed = 1\n",
    "    log_interval = 5\n",
    "    save_model = True\n",
    "    no_cuda = False\n",
    "    \n",
    "    use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "    torch.manual_seed(seed)\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    model = ResNet(block=BasicBlock, layers=[2, 2, 2, 2], num_classes=10, mnist=True).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    args = {}\n",
    "    args[\"log_interval\"] = log_interval\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "\n",
    "    if (save_model):\n",
    "        torch.save(model.state_dict(),\"mnist_cnn.pt\")\n",
    "\n",
    "# main_18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_50():\n",
    " \n",
    "    batch_size = 64\n",
    "    epochs = 1\n",
    "    lr = 0.01\n",
    "    momentum = 0.5\n",
    "    seed = 1\n",
    "    log_interval = 5\n",
    "    save_model = True\n",
    "    no_cuda = False\n",
    "    \n",
    "    use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "    torch.manual_seed(seed)\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    model = ResNet(block=Bottleneck, layers=[3, 4, 6, 3], num_classes=10, mnist=True).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    args = {}\n",
    "    args[\"log_interval\"] = log_interval\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        break\n",
    "\n",
    "    if (save_model):\n",
    "        torch.save(model.state_dict(),\"mnist_cnn.pt\")\n",
    "        \n",
    "\n",
    "    return model\n",
    "\n",
    "# model = main_50()\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_size_of_model(model):\n",
    "    \"\"\" Print the size of the model.\n",
    "    \n",
    "    Args:\n",
    "        model: model whose size needs to be determined\n",
    "\n",
    "    \"\"\"\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size of the model(MB):', os.path.getsize(\"temp.p\")/1e6)\n",
    "    os.remove('temp.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, quantize=False, fbgemm=False):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Testing with qauntization if quantize=True\n",
    "    if quantize:\n",
    "        modules_to_fuse_old = [['conv1', 'bn1'],\n",
    "                   ['layer1.0.conv1', 'layer1.0.bn1'],\n",
    "                   ['layer1.0.conv2', 'layer1.0.bn2'],\n",
    "                   ['layer1.1.conv1', 'layer1.1.bn1'],\n",
    "                   ['layer1.1.conv2', 'layer1.1.bn2'],\n",
    "                   ['layer2.0.conv1', 'layer2.0.bn1'],\n",
    "                   ['layer2.0.conv2', 'layer2.0.bn2'],\n",
    "                   ['layer2.0.downsample.0', 'layer2.0.downsample.1'],\n",
    "                   ['layer2.1.conv1', 'layer2.1.bn1'],\n",
    "                   ['layer2.1.conv2', 'layer2.1.bn2'],\n",
    "                   ['layer3.0.conv1', 'layer3.0.bn1'],\n",
    "                   ['layer3.0.conv2', 'layer3.0.bn2'],\n",
    "                   ['layer3.0.downsample.0', 'layer3.0.downsample.1'],\n",
    "                   ['layer3.1.conv1', 'layer3.1.bn1'],\n",
    "                   ['layer3.1.conv2', 'layer3.1.bn2'],\n",
    "                   ['layer4.0.conv1', 'layer4.0.bn1'],\n",
    "                   ['layer4.0.conv2', 'layer4.0.bn2'],\n",
    "                   ['layer4.0.downsample.0', 'layer4.0.downsample.1'],\n",
    "                   ['layer4.1.conv1', 'layer4.1.bn1'],\n",
    "                   ['layer4.1.conv2', 'layer4.1.bn2']]\n",
    "        model = torch.quantization.fuse_modules(model, modules_to_fuse_old)\n",
    "        if fbgemm:\n",
    "            model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "        else:\n",
    "            model.qconfig = torch.quantization.default_qconfig\n",
    "        torch.quantization.prepare(model, inplace=True)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data, target in train_loader:\n",
    "                model(data)\n",
    "        torch.quantization.convert(model, inplace=True)\n",
    "\n",
    "    print(model)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    index = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            index += 1\n",
    "            print(index, datetime.now())\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            st = time.time()\n",
    "            output = model(data)\n",
    "            et = time.time()\n",
    "            test_loss += F.nll_loss(F.log_softmax(output, dim=-1), target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    print(\"========================================= PERFORMANCE =============================================\")\n",
    "    print_size_of_model(model)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    print('Elapsed time = {:0.4f} milliseconds'.format((et - st) * 1000))\n",
    "    print(\"====================================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline performance - unquantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "encoder_18 = ResNet(num_classes=10, mnist=True)\n",
    "loaded_dict_enc_18 = torch.load('mnist_cnn-resnet18.pt', map_location=device)\n",
    "encoder_18.load_state_dict(loaded_dict_enc_18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (quant): QuantStub()\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "  (quant): QuantStub()\n",
      "  (dequant): DeQuantStub()\n",
      ")\n",
      "========================================= PERFORMANCE =============================================\n",
      "Size of the model(MB): 44.782195\n",
      "\n",
      "Test set: Average loss: 0.0325, Accuracy: 9897/10000 (99%)\n",
      "\n",
      "Elapsed time = 28.4178 milliseconds\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "test(model=encoder, device=device, test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): QuantizedConv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.12347077578306198, zero_point=61, padding=(3, 3))\n",
      "  (bn1): Identity()\n",
      "  (relu): QuantizedReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.10298416018486023, zero_point=60, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.10945683717727661, zero_point=61, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.13676385581493378, zero_point=47\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.09816549718379974, zero_point=61, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.10349876433610916, zero_point=62, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.15333621203899384, zero_point=42\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.11402199417352676, zero_point=66, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.09683991968631744, zero_point=63, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), scale=0.1252516359090805, zero_point=57)\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.18063707649707794, zero_point=55\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.10193919390439987, zero_point=63, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.10610567033290863, zero_point=63, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.1506330966949463, zero_point=41\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.10301125049591064, zero_point=64, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.07678677886724472, zero_point=63, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), scale=0.12266261130571365, zero_point=66)\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.13961999118328094, zero_point=60\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.07777702808380127, zero_point=63, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.08191445469856262, zero_point=62, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.12591896951198578, zero_point=40\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.08079221844673157, zero_point=64, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.08426522463560104, zero_point=64, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.08299878984689713, zero_point=60)\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.12526896595954895, zero_point=56\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.0760582759976387, zero_point=63, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.08169588446617126, zero_point=64, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.12883007526397705, zero_point=41\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): QuantizedLinear(in_features=512, out_features=10, scale=0.24648116528987885, zero_point=34, qscheme=torch.per_tensor_affine)\n",
      "  (quant): Quantize(scale=tensor([0.0256]), zero_point=tensor([17]), dtype=torch.quint8)\n",
      "  (dequant): DeQuantize()\n",
      ")\n",
      "========================================= PERFORMANCE =============================================\n",
      "Size of the model(MB): 11.220779\n",
      "\n",
      "Test set: Average loss: 0.0338, Accuracy: 9891/10000 (99%)\n",
      "\n",
      "Elapsed time = 11.2729 milliseconds\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "encoder = ResNet(num_classes=10, mnist=True, quantize=True)\n",
    "loaded_dict_enc = torch.load('mnist_cnn-resnet18.pt', map_location=device)\n",
    "encoder.load_state_dict(loaded_dict_enc)\n",
    "test(model=encoder, device=device, test_loader=test_loader, quantize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16/40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "encoder2 = ResNet(block=Bottleneck, layers=[3, 4, 6, 3], num_classes=10, mnist=True).to(device)\n",
    "loaded_dict_enc = torch.load('mnist_cnn.pt', map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder2.load_state_dict(loaded_dict_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "encoder_50 = ResNet(block=Bottleneck, layers=[3, 4, 6, 3], num_classes=10, mnist=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_dict_enc_50 = torch.load('mnist_cnn-resnet50.pt', map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_dict_enc_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_50.load_state_dict(loaded_dict_enc_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64, 1, 1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_dict_enc_50['layer1.0.conv1.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64, 3, 3])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_dict_enc_18['layer1.0.conv1.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
      "  (quant): QuantStub()\n",
      "  (dequant): DeQuantStub()\n",
      ")\n",
      "1 2020-10-07 21:51:14.165916\n",
      "2 2020-10-07 21:51:14.448524\n",
      "3 2020-10-07 21:51:14.689804\n",
      "4 2020-10-07 21:51:14.923973\n",
      "5 2020-10-07 21:51:15.159703\n",
      "6 2020-10-07 21:51:15.385211\n",
      "7 2020-10-07 21:51:15.619260\n",
      "8 2020-10-07 21:51:15.836410\n",
      "9 2020-10-07 21:51:16.122643\n",
      "10 2020-10-07 21:51:16.435500\n",
      "11 2020-10-07 21:51:16.751565\n",
      "12 2020-10-07 21:51:17.026251\n",
      "13 2020-10-07 21:51:17.241330\n",
      "14 2020-10-07 21:51:17.485335\n",
      "15 2020-10-07 21:51:17.747457\n",
      "16 2020-10-07 21:51:17.969076\n",
      "17 2020-10-07 21:51:18.188198\n",
      "18 2020-10-07 21:51:18.423812\n",
      "19 2020-10-07 21:51:18.648556\n",
      "20 2020-10-07 21:51:18.870856\n",
      "21 2020-10-07 21:51:19.170989\n",
      "22 2020-10-07 21:51:19.488663\n",
      "23 2020-10-07 21:51:19.796127\n",
      "24 2020-10-07 21:51:20.074508\n",
      "25 2020-10-07 21:51:20.379250\n",
      "26 2020-10-07 21:51:20.681718\n",
      "27 2020-10-07 21:51:21.000618\n",
      "28 2020-10-07 21:51:21.297860\n",
      "29 2020-10-07 21:51:21.592471\n",
      "30 2020-10-07 21:51:21.885040\n",
      "31 2020-10-07 21:51:22.185132\n",
      "32 2020-10-07 21:51:22.466355\n",
      "33 2020-10-07 21:51:22.747386\n",
      "34 2020-10-07 21:51:22.969833\n",
      "35 2020-10-07 21:51:23.286700\n",
      "36 2020-10-07 21:51:23.582603\n",
      "37 2020-10-07 21:51:23.845507\n",
      "38 2020-10-07 21:51:24.069941\n",
      "39 2020-10-07 21:51:24.330815\n",
      "40 2020-10-07 21:51:24.618091\n",
      "41 2020-10-07 21:51:24.892564\n",
      "42 2020-10-07 21:51:25.114905\n",
      "43 2020-10-07 21:51:25.411494\n",
      "44 2020-10-07 21:51:25.671800\n",
      "45 2020-10-07 21:51:25.899278\n",
      "46 2020-10-07 21:51:26.120516\n",
      "47 2020-10-07 21:51:26.371446\n",
      "48 2020-10-07 21:51:26.631613\n",
      "49 2020-10-07 21:51:26.935066\n",
      "50 2020-10-07 21:51:27.228035\n",
      "51 2020-10-07 21:51:27.515601\n",
      "52 2020-10-07 21:51:27.743947\n",
      "53 2020-10-07 21:51:27.977094\n",
      "54 2020-10-07 21:51:28.240515\n",
      "55 2020-10-07 21:51:28.489516\n",
      "56 2020-10-07 21:51:28.731078\n",
      "57 2020-10-07 21:51:28.958233\n",
      "58 2020-10-07 21:51:29.194656\n",
      "59 2020-10-07 21:51:29.431282\n",
      "60 2020-10-07 21:51:29.669628\n",
      "61 2020-10-07 21:51:29.978990\n",
      "62 2020-10-07 21:51:30.286403\n",
      "63 2020-10-07 21:51:30.545104\n",
      "64 2020-10-07 21:51:30.780643\n",
      "65 2020-10-07 21:51:31.014182\n",
      "66 2020-10-07 21:51:31.283699\n",
      "67 2020-10-07 21:51:31.514291\n",
      "68 2020-10-07 21:51:31.745231\n",
      "69 2020-10-07 21:51:31.975723\n",
      "70 2020-10-07 21:51:32.207782\n",
      "71 2020-10-07 21:51:32.508767\n",
      "72 2020-10-07 21:51:32.800090\n",
      "73 2020-10-07 21:51:33.026376\n",
      "74 2020-10-07 21:51:33.255308\n",
      "75 2020-10-07 21:51:33.505704\n",
      "76 2020-10-07 21:51:33.741367\n",
      "77 2020-10-07 21:51:33.963145\n",
      "78 2020-10-07 21:51:34.216518\n",
      "79 2020-10-07 21:51:34.453190\n",
      "80 2020-10-07 21:51:34.680970\n",
      "81 2020-10-07 21:51:34.918951\n",
      "82 2020-10-07 21:51:35.161446\n",
      "83 2020-10-07 21:51:35.399277\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-e3c1c3cf65ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-50-1cd6d7737396>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, device, test_loader, quantize, fbgemm)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0met\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mtest_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# sum up batch loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zhao/teaching/samhitha.m-ML/resnet18/.venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-c1dc31d90f3f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m          \u001b[0;31m# See note [TorchScript super()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-c1dc31d90f3f>\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zhao/teaching/samhitha.m-ML/resnet18/.venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zhao/teaching/samhitha.m-ML/resnet18/.venv/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zhao/teaching/samhitha.m-ML/resnet18/.venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-ded951ee7b1a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zhao/teaching/samhitha.m-ML/resnet18/.venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zhao/teaching/samhitha.m-ML/resnet18/.venv/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zhao/teaching/samhitha.m-ML/resnet18/.venv/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    414\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    415\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 416\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test(model=encoder_50, device=device, test_loader=test_loader, quantize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): QuantizedConv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.09478211402893066, zero_point=60, padding=(3, 3))\n",
      "  (bn1): Identity()\n",
      "  (relu): QuantizedReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): QuantizedConv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.09513133019208908, zero_point=60)\n",
      "      (bn1): Identity()\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.10012965649366379, zero_point=62, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (conv3): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.07041231542825699, zero_point=58, bias=False)\n",
      "      (bn3): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.13869887590408325, zero_point=60, bias=False)\n",
      "        (1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): QuantizedConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.0986124649643898, zero_point=64)\n",
      "      (bn1): Identity()\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.0942753478884697, zero_point=58, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (conv3): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.06805780529975891, zero_point=61, bias=False)\n",
      "      (bn3): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): QuantizedConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.38257089257240295, zero_point=63, bias=False)\n",
      "      (bn1): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.13908971846103668, zero_point=59, padding=(1, 1), bias=False)\n",
      "      (bn2): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.07316046953201294, zero_point=60, bias=False)\n",
      "      (bn3): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): QuantizedConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.10137566924095154, zero_point=64)\n",
      "      (bn1): Identity()\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.10575142502784729, zero_point=62, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.07038336247205734, zero_point=66, bias=False)\n",
      "      (bn3): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.12536703050136566, zero_point=62)\n",
      "        (1): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): QuantizedConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.1403728872537613, zero_point=71)\n",
      "      (bn1): Identity()\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.09229756891727448, zero_point=60, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.06549376994371414, zero_point=64, bias=False)\n",
      "      (bn3): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): QuantizedConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.48405367136001587, zero_point=65, bias=False)\n",
      "      (bn1): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.12456737458705902, zero_point=57, padding=(1, 1), bias=False)\n",
      "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.05692711099982262, zero_point=64, bias=False)\n",
      "      (bn3): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): QuantizedConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.5242753028869629, zero_point=59, bias=False)\n",
      "      (bn1): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.11275477707386017, zero_point=58, padding=(1, 1), bias=False)\n",
      "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.06250842660665512, zero_point=65, bias=False)\n",
      "      (bn3): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): QuantizedConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.11806924641132355, zero_point=58)\n",
      "      (bn1): Identity()\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.09779255837202072, zero_point=57, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.06820956617593765, zero_point=67, bias=False)\n",
      "      (bn3): QuantizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), scale=0.11253613978624344, zero_point=65)\n",
      "        (1): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): QuantizedConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.1026533991098404, zero_point=61)\n",
      "      (bn1): Identity()\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.08919564634561539, zero_point=61, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.05906491354107857, zero_point=61, bias=False)\n",
      "      (bn3): QuantizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): QuantizedConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.47671815752983093, zero_point=67, bias=False)\n",
      "      (bn1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.09260159730911255, zero_point=59, padding=(1, 1), bias=False)\n",
      "      (bn2): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.07071706652641296, zero_point=65, bias=False)\n",
      "      (bn3): QuantizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): QuantizedConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.5772301554679871, zero_point=59, bias=False)\n",
      "      (bn1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.08362268656492233, zero_point=59, padding=(1, 1), bias=False)\n",
      "      (bn2): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.06816858053207397, zero_point=62, bias=False)\n",
      "      (bn3): QuantizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): QuantizedConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.6259303092956543, zero_point=69, bias=False)\n",
      "      (bn1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.09437760710716248, zero_point=54, padding=(1, 1), bias=False)\n",
      "      (bn2): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.08040989935398102, zero_point=62, bias=False)\n",
      "      (bn3): QuantizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): QuantizedConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.7774021625518799, zero_point=64, bias=False)\n",
      "      (bn1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.10486629605293274, zero_point=51, padding=(1, 1), bias=False)\n",
      "      (bn2): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.07875140756368637, zero_point=63, bias=False)\n",
      "      (bn3): QuantizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): QuantizedConv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.11965334415435791, zero_point=61)\n",
      "      (bn1): Identity()\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.12771934270858765, zero_point=60, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (conv3): QuantizedConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), scale=0.11795345693826675, zero_point=66, bias=False)\n",
      "      (bn3): QuantizedBatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), scale=0.11911536753177643, zero_point=63)\n",
      "        (1): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): QuantizedConv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.15345261991024017, zero_point=57)\n",
      "      (bn1): Identity()\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.1646316796541214, zero_point=61, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (conv3): QuantizedConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), scale=0.15784719586372375, zero_point=64, bias=False)\n",
      "      (bn3): QuantizedBatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): QuantizedConv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.8580076098442078, zero_point=58, bias=False)\n",
      "      (bn1): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.1125715970993042, zero_point=66, padding=(1, 1), bias=False)\n",
      "      (bn2): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): QuantizedConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), scale=0.20573467016220093, zero_point=56, bias=False)\n",
      "      (bn3): QuantizedBatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): QuantizedLinear(in_features=2048, out_features=10, scale=0.3185722827911377, zero_point=49, qscheme=torch.per_tensor_affine)\n",
      "  (quant): Quantize(scale=tensor([1.]), zero_point=tensor([0]), dtype=torch.quint8)\n",
      "  (dequant): DeQuantize()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaojun/zhao/teaching/samhitha.m-ML/resnet18/.venv/lib/python3.7/site-packages/torch/quantization/observer.py:136: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  Returning default scale and zero point \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2020-10-07 21:55:27.231863\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Could not run 'quantized::conv2d.new' with arguments from the 'CPU' backend. 'quantized::conv2d.new' is only available for these backends: [QuantizedCPU].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-8c18736a9dfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-50-1cd6d7737396>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, device, test_loader, quantize, fbgemm)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0met\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mtest_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# sum up batch loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zhao/teaching/samhitha.m-ML/resnet18/.venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-c1dc31d90f3f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m          \u001b[0;31m# See note [TorchScript super()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-c1dc31d90f3f>\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zhao/teaching/samhitha.m-ML/resnet18/.venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zhao/teaching/samhitha.m-ML/resnet18/.venv/lib/python3.7/site-packages/torch/nn/quantized/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input shape must be `(N, C, H, W)`!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         return ops.quantized.conv2d(\n\u001b[0;32m--> 327\u001b[0;31m             input, self._packed_params, self.scale, self.zero_point)\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not run 'quantized::conv2d.new' with arguments from the 'CPU' backend. 'quantized::conv2d.new' is only available for these backends: [QuantizedCPU]."
     ]
    }
   ],
   "source": [
    "test(model=encoder_50, device=device, test_loader=test_loader, quantize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
